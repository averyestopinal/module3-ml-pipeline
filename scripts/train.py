"""
train.py: 
- Reads data/cleaned/.
- Trains RandomForestRegressor model on data
- Saves artifacts/model.joblib.

Citation: 

OpenAI. (2025, November 22). ChatGPT response to a request for regression model evaluation metrics [Large language model]. https://chat.openai.com/
This cited block studies model accuracy

OpenAI. (2025, November 22). ChatGPT (Version 5.1) [Large language model]. https://chat.openai.com
Code for training a RandomForestRegressor with Weights & Biases logging, including evaluation metrics and artifact tracking. Conversation used to generate train.py script for Module 3 Project.


"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import joblib
import yaml
from sklearn.ensemble import RandomForestRegressor
import pandas as pd
import wandb
import os
import json

# W and B tracking of model
run = wandb.init(
    # Set the wandb entity where your project will be logged (generally your team name).
    entity="ace40-duke-university",
    # Set the wandb project where this run will be logged.
    project="Module-Project-3",
    # Track hyperparameters and run metadata.
    config={
        "model_type": "RandomForestRegressor",
        "n_estimators": 100,
        "dataset": "cleaned coffee data",
    }
    # Config built by ChatGOT 5.1 at 9:13p on 11/22/25.
)

with open("config.yaml", "r") as f:
    config = yaml.safe_load(f)

MODEL_PATH = config["paths"]["artifacts"]["model"]
METRICS_PATH = config["paths"]["artifacts"]["metrics"]
PREPROCESSOR_PATH = config["paths"]["artifacts"]["preprocessor"]


# Using yaml to define paths
xtrain_path = config["paths"]["X_train"]
xtest_path = config["paths"]["X_test"]
ytrain_path = config["paths"]["y_train"]
ytest_path = config["paths"]["y_test"]

# Load X_train, X_test, y_train, y_test from data/cleaned
X_train = pd.read_csv(xtrain_path)
X_test = pd.read_csv(xtest_path)
y_train = pd.read_csv(ytrain_path).squeeze()
y_test = pd.read_csv(ytest_path).squeeze()
# The above code snippet was generated by ChatGPT 5.1 at 8:22p on 11/22/25.

model_params = config.get("train", {}).get("model_params", {})
# Model selection
model = RandomForestRegressor(**model_params)

# Fitting model to X_train, y_train
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Printing model acccuracy: Returns 94.7%
# print(model.score(X_test, y_test))

# Begin cited block: OpenAI. (2025, November 22). ChatGPT response to a request for regression model evaluation metrics [Large language model]. https://chat.openai.com/
# This cited block studies model accuracy
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

#------------------------------------END CITED BLOCK-----------------------


# Cited block: OpenAI. (2025, November 22). ChatGPT (Version 5.1) [Large language model]. https://chat.openai.com
# Code for training a RandomForestRegressor with Weights & Biases logging, including evaluation metrics and artifact tracking. Conversation used to generate train.py script for Module 3 Project.
run.log({
    "R2": r2,
    "RMSE": rmse,
    "MAE": mae,
    "MAPE": mape
})

# Saving model to artifacts
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
joblib.dump(model, MODEL_PATH)

# Saving metrics to artifacts
os.makedirs(os.path.dirname(METRICS_PATH), exist_ok=True)
json.dump(metrics_dict, f, indent=4)

# Saving preprocessor to artifacts
os.makedirs(os.path.dirname(PREPROCESSOR_PATH), exist_ok=True)
joblib.dump(model, MODEL_PATH)


artifact = wandb.Artifact("random_forest_model", type="model")
artifact.add_file(MODEL_PATH)
run.log_artifact(artifact)
# ------------------------END CITED BLOCK-----------------------

# The above code snippet was generated by chatGPT 5.1 at 6:16p on 11/22/25.

run.finish()