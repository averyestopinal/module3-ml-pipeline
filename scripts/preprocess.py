import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

df = pd.read_csv('data/preprocessed/preprocessed_data.csv')

numeric_cols = ["Number.of.Bags", "Category.One.Defects", "Category.Two.Defects", "Aroma", "Flavor", "Aftertaste", "Acidity", "Body", "Balance", "Uniformity", "Clean.Cup", "Sweetness", "Cupper.Points", "Moisture",
"Quakers", "altitude_low_meters", "altitude_high_meters", "altitude_mean_meters"]
categorical_cols = ["Species", "Owner", "Country.of.Origin", "Mill", "ICO.Number", "Company", "Altitude", "Region", "Producer", "Bag.Weight", "In.Country.Partner",
"Harvest.Year", "Grading.Date", "Owner.1", "Variety", "Processing.Method", "Color", "Expiration", "Certification.Body", "Certification.Address",
"Certification.Contact", "unit_of_measurement"]

"""
The below block of code was derived from AIPI503 - Ed Lessons Day 4 Challenge
This course was taught by Dr. Daniel E. Davis, Ph.D.
"""

X = df.drop(columns=["Total.Cup.Points"])
y = df["Total.Cup.Points"]


train_df, test_df, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def preprocess(train_df, test_df, numeric_cols, categorical_cols):
    imputer_num = SimpleImputer(strategy="median")
    train_num_imp = imputer_num.fit_transform(train_df[numeric_cols])
    test_num_imp = imputer_num.transform(test_df[numeric_cols])

    scaler_num = StandardScaler()
    train_num_scaled = scaler_num.fit_transform(train_num_imp)
    test_num_scaled = scaler_num.transform(test_num_imp)

    imputer_cat = SimpleImputer(strategy="most_frequent")
    train_cat_imp = imputer_cat.fit_transform(train_df[categorical_cols])
    test_cat_imp = imputer_cat.transform(test_df[categorical_cols])

    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    train_cat_enc = ohe.fit_transform(train_cat_imp)
    test_cat_enc = ohe.transform(test_cat_imp)

    ohe_feature_names = ohe.get_feature_names_out(categorical_cols)

    feature_names = list(numeric_cols) + list(ohe_feature_names)
    X_train = np.hstack([train_num_scaled, train_cat_enc])
    X_test  = np.hstack([test_num_scaled,  test_cat_enc])
    # The above code snipet was generated by chatGPT 5.1 at 12:07p on 11/20/25.
    
    X_train_df = pd.DataFrame(X_train, columns=feature_names, index=train_df.index)
    X_test_df  = pd.DataFrame(X_test,  columns=feature_names, index=test_df.index)
    # The above code snipet was generated by chatGPT 5.1 at 12:27p on 11/20/25.

    X_train_df.to_csv("data/cleaned/X_train.csv", index=False)
    X_test_df.to_csv("data/cleaned/X_test.csv", index=False)
    y_train.to_csv("data/cleaned/y_train.csv", index=False)
    y_test.to_csv("data/cleaned/y_test.csv", index=False)

    return X_train, X_test, feature_names, imputer_num, scaler_num, imputer_cat, ohe

"""
End cited block
"""

preprocess(train_df, test_df, numeric_cols, categorical_cols)